{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc7ef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\priya\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\priya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas \n",
    "pip install scipy\n",
    "pip install matplotlib\n",
    "pip install ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import periodogram\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06217b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset file into a dataframe called 'data'\n",
    "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Sub_Division_IMD_2017.csv')\n",
    "display(data)    #  Displaying the DataFrame that we just read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94fa2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration:\n",
    "# After inspecting the data, I see that the data is of 117 years of only some selected states in India, with their rainfall data for each month.\n",
    "# The data ranges from 1901-2017. With a data of 100+ years, we can analyze various aspects.\n",
    "\n",
    "# Analytical Goals:\n",
    "# 1. Long-term trend\n",
    "# 2. Seasonal Pattern\n",
    "# 3. Months with max-min rainfall and variability\n",
    "# 4. Extreme events in our centurial data\n",
    "# 5. State-wise analysis\n",
    "# 6. Trend-line (direction and pattern of my data)\n",
    "# 7. Cyclic patterns\n",
    "# 8. Comparing two different months of the same and different years\n",
    "# 9. Time-series of the state with max-min rainfall and understanding the pattern for the same\n",
    "# 10. Spatial Analysis\n",
    "# 11. Forecast the future rainfall patterns\n",
    "# 12. Grouping the data into groups of 15-20 years and analyzing the variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# omitting last 4 columns (JF,MAM,JJA, OND)\n",
    "data1 = data.iloc[:, :-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Uttarakhand = (data1 == 'Uttarakhand').any(axis=1)\n",
    "Uttarakhand = data1[Uttarakhand]\n",
    "\n",
    "mean_value = np.mean(Uttarakhand['ANNUAL'])\n",
    "print(mean_value)\n",
    "median_value = np.median(Uttarakhand['ANNUAL'])\n",
    "print(median_value)\n",
    "\n",
    "std_dev = np.std(Uttarakhand['ANNUAL'])\n",
    "print(std_dev)\n",
    "variance = np.var(Uttarakhand['ANNUAL'])\n",
    "print(variance)\n",
    "\n",
    "skewness = Uttarakhand['ANNUAL'].skew()\n",
    "print(skewness)\n",
    "kurtosis = Uttarakhand['ANNUAL'].kurt()\n",
    "print(kurtosis)\n",
    "\n",
    "minimum = np.min(Uttarakhand['ANNUAL'])\n",
    "print(minimum)\n",
    "maximum = np.max(Uttarakhand['ANNUAL'])\n",
    "print(maximum)\n",
    "\n",
    "q1 = np.percentile(Uttarakhand['ANNUAL'] , 25)\n",
    "print(q1)\n",
    "q3 = np.percentile(Uttarakhand['ANNUAL'] , 75)\n",
    "print(q3)\n",
    "\n",
    "iqr = q3 - q1\n",
    "print(iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot for all columns\n",
    "data1.boxplot(rot=45, figsize=(12, 8))\n",
    "plt.title('Box Plot for Each Column')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Box-plot( box-and-whisker plot) helps us to visualize the distribution of data\n",
    "# helps visualize the spread, skewness, and central tendency of the data\n",
    "# We can see outliers in our box-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b540f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outlier rejection\n",
    "\n",
    "# Set a threshold for Z-scores (e.g., 3)\n",
    "threshold = 3\n",
    "\n",
    "# Create an empty DataFrame to store outliers\n",
    "outliers_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each numeric column\n",
    "for column_name in data1.select_dtypes(include=np.number).columns:\n",
    "    # Calculate Z-scores\n",
    "    z_scores = np.abs((data1[column_name] - data1[column_name].mean()) / data1[column_name].std())\n",
    "\n",
    "    # Identify outliers\n",
    "    column_outliers = data1[z_scores > threshold]\n",
    "\n",
    "    # Append outliers to the outliers_df\n",
    "    outliers_df = pd.concat([outliers_df, column_outliers])\n",
    "\n",
    "# Remove duplicates from outliers_df\n",
    "outliers_df = outliers_df.drop_duplicates()\n",
    "\n",
    "# Remove outliers from the original DataFrame\n",
    "df_cleaned = data1.drop(outliers_df.index)\n",
    "\n",
    "# Display information about removed outliers\n",
    "print(f'Number of outliers removed: {len(outliers_df)}')\n",
    "print('Outliers:')\n",
    "print(outliers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c778f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot for all columns\n",
    "df_cleaned.boxplot(rot=45, figsize=(12, 8))\n",
    "plt.title('Box Plot for Each Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e445e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Seasonal Analysis\n",
    "\n",
    "# Reading the set again , In this analysis I', using the last 4 columns of my set\n",
    "# I'm plotting months with time \n",
    "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Sub_Division_IMD_2017.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# as i have more than 20 states, choosing single state and analyzing which seasons have max-min rainfall and variability\n",
    "# JF  - Jan and feb\n",
    "# MAM - mar, april and may\n",
    "# JJAS - june, june , august and september\n",
    "# OND - october, november and december \n",
    "seasons = (df == 'Uttarakhand').any(axis=1)\n",
    "seasons = df[seasons]\n",
    "\n",
    "# Omitting the rest of the columns\n",
    "seasons =  seasons.iloc[:, :2].join(seasons.iloc[:, -4:])\n",
    "seasons.plot( x = 'YEAR' , figsize=(30,10), linestyle = '--' , marker = '.')\n",
    "\n",
    "# the graph shows JUNE, JULY, AUGUST AND SEPT are the months with max rainfall\n",
    "# we can conclude JJAS - rainy season in india(uttarakhand)\n",
    "# we can check for all the states similary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f36e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal patterns\n",
    "\"\"\"\n",
    "To find seasonal patterns in a rainfall dataset spanning 100 years, I am using time series analysis\n",
    "seasonal decomposition, which separates the data into its underlying components:\n",
    "trend, seasonal, and residual.\n",
    "Trend will help us look for long-term patterns or trends in the data, if it is increasing, decreasing, or relatively stable over time?\n",
    "Seasonal helps us Identify repeating patterns that occur at regular intervals, seasonality can be noted with the peaks and trough\n",
    "Residual Checks for any remaining patterns or irregularities in the data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "Uttarakhand_cleaned = (df_cleaned == 'Uttarakhand').any(axis=1)\n",
    "Uttarakhand_cleaned = df_cleaned[Uttarakhand_cleaned]\n",
    "print(Uttarakhand_cleaned)\n",
    "\n",
    "decomposition = seasonal_decompose(Uttarakhand['ANNUAL'], model = 'multiplicative', period = 12)\n",
    "plt.figure(figsize = (20,8))\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(Uttarakhand.index, decomposition.trend, label='Trend', color = 'blue')\n",
    "plt.legend()\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(Uttarakhand.index, decomposition.seasonal, label='seasonal', color = 'green')\n",
    "plt.legend()\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(Uttarakhand.index, decomposition.resid, label='residual', color = 'red')\n",
    "plt.legend()\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(Uttarakhand.index, Uttarakhand['ANNUAL'], label='original', color = 'black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccf09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
